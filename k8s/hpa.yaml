# Horizontal Pod Autoscaler configuration for a Kubernetes deployment
# This configuration will scale the Pod based on CPU utilization
# Ensure you have the Horizontal Pod Autoscaler (HPA) enabled in your cluster
# Make sure to apply this configuration after deploying your application
# Horizontal Pod Autoscaler for the NLP application

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nlp-app
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nlp-app
  minReplicas: 1                # keep costs low when idle
  maxReplicas: 2                # allow bursts (tune as needed)
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 90
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 200             # can double quickly under load
          periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 50              # back off gradually to avoid thrash
          periodSeconds: 60

